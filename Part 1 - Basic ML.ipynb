{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Manipulation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Array with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T01:54:54.205718Z",
     "start_time": "2019-05-13T01:54:54.203319Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T01:54:55.001374Z",
     "start_time": "2019-05-13T01:54:54.997814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "t = np.array([0., 1., 2., 3., 4., 5., 6., 7])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T01:54:56.575372Z",
     "start_time": "2019-05-13T01:54:56.572330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of t: 1\n",
      "Shape of t: (8,)\n"
     ]
    }
   ],
   "source": [
    "print('Rank of t:', t.ndim)\n",
    "print('Shape of t:', t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T01:54:57.058821Z",
     "start_time": "2019-05-13T01:54:57.053307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t[0]\tt[1]\tt[-1] =\t 0.0 1.0 7.0\n",
      "t[2:5]\tt[4:-1]\t=\t [2. 3. 4.] [4. 5. 6.]\n",
      "t[:2]\tt[3:] =\t [0. 1.] [3. 4. 5. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "print('t[0]\\tt[1]\\tt[-1] =\\t', t[0], t[1], t[-1])    # Element\n",
    "print('t[2:5]\\tt[4:-1]\\t=\\t', t[2:5], t[4:-1])    # Slicing\n",
    "print('t[:2]\\tt[3:] =\\t', t[:2], t[3:])    # Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Array with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T01:54:58.888556Z",
     "start_time": "2019-05-13T01:54:58.884167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T01:54:59.591070Z",
     "start_time": "2019-05-13T01:54:59.587846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of t: 2\n",
      "Shape of t: (4, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Rank of t:', t.ndim)\n",
    "print('Shape of t:', t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Array with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T01:55:00.936664Z",
     "start_time": "2019-05-13T01:55:00.786735Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T01:55:01.953353Z",
     "start_time": "2019-05-13T01:55:01.928609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7.])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6., 7.])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:00:27.678414Z",
     "start_time": "2019-05-13T02:00:27.670241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "tensor(0.) tensor(1.) tensor(7.)\n",
      "tensor([2., 3., 4.]) tensor([4., 5., 6.])\n",
      "tensor([0., 1.]) tensor([3., 4., 5., 6., 7.])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim())  # Rank\n",
    "print(t.shape)  # Shape\n",
    "print(t.size())  # Shape\n",
    "print(t[0], t[1], t[-1])  # Element\n",
    "print(t[2:5], t[4:-1])  # Slicing\n",
    "print(t[:2], t[3:])  # Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Array with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:05:42.559144Z",
     "start_time": "2019-05-13T02:05:42.554595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:06:38.459947Z",
     "start_time": "2019-05-13T02:06:38.441898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n",
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim())  # Rank\n",
    "print(t.size())  # shape\n",
    "print(t[:, 1])    # (All dims, 1)\n",
    "print(t[:, 1].size())    # (All dims, 1)\n",
    "print(t[:, :-1])    # (All dims, ~except last) = (4, ~2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:42:40.056098Z",
     "start_time": "2019-05-13T02:42:40.051923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Same shape\n",
    "m1 = torch.FloatTensor([[3, 3]])\n",
    "m2 = torch.FloatTensor([[2, 2]])\n",
    "print(m1 + m2)    # ([[3+2, 3+2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:43:59.089023Z",
     "start_time": "2019-05-13T02:43:59.084905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Vector + scalar\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([3])  # 3 → [[3, 3]]\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:44:51.997827Z",
     "start_time": "2019-05-13T02:44:51.993622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# 2 x 1 Vector + 1 x 2 Vector\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([[3], [4]])\n",
    "print(m1 + m2)    # ([[1 + 3, 1 + 4], [2 + 3, 2 + 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplication vs Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:52:45.195255Z",
     "start_time": "2019-05-13T02:52:45.160276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------\n",
      "Mul vs Matmul\n",
      "---------------\n",
      "Shape of Matrix 1: torch.Size([2, 2])\n",
      "Shape of Matrix 2: torch.Size([2, 2])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n",
      "Shape of Matrix 1: torch.Size([2, 2])\n",
      "Shape of Matrix 2: torch.Size([2, 2])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('-' * 15)\n",
    "print('Mul vs Matmul')\n",
    "print('-' * 15)\n",
    "\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1:', m1.shape)    # 2 x 2\n",
    "print('Shape of Matrix 2:', m1.shape)    # 2 x 1\n",
    "print(m1.matmul(m2))  # 2 x 1\n",
    "\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1:', m1.shape)    # 2 x 2\n",
    "print('Shape of Matrix 2:', m1.shape)    # 2 x 1\n",
    "print(m1 * m2)\n",
    "print(m1.mul(m2))  # 2 x 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:53:52.948351Z",
     "start_time": "2019-05-13T02:53:52.930863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([1, 2])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:54:42.886082Z",
     "start_time": "2019-05-13T02:54:42.880070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can only calculate the mean of floating types. Got Long instead.\n"
     ]
    }
   ],
   "source": [
    "# Can't use mean on integers\n",
    "t = torch.LongTensor([1, 2])\n",
    "try:\n",
    "    print(t.mean())\n",
    "except Exception as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`t.mean`은 특정 dimension이나 모든 element에 대한 평균을 구할때도 쓰인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:55:57.796379Z",
     "start_time": "2019-05-13T02:55:57.792331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:56:15.767645Z",
     "start_time": "2019-05-13T02:56:15.761156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "print(t.mean())\n",
    "print(t.mean(dim=0))\n",
    "print(t.mean(dim=1))\n",
    "print(t.mean(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:56:58.564551Z",
     "start_time": "2019-05-13T02:56:58.560770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:57:25.125184Z",
     "start_time": "2019-05-13T02:57:25.107870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "print(t.sum())\n",
    "print(t.sum(dim=0))\n",
    "print(t.sum(dim=1))\n",
    "print(t.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max and Argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:58:22.188209Z",
     "start_time": "2019-05-13T02:58:22.184422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max`연산자는 argument가 지정되지 않을시 하나의 값만을 리턴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T02:59:12.256668Z",
     "start_time": "2019-05-13T02:59:12.253145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "print(t.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max`연산자는 dimension이 지정될 시, 두개의 값을 리턴한다. 첫번째 값은 최대 value이며, 두번째는 argmax이다. (최대값의 index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:01:13.909363Z",
     "start_time": "2019-05-13T03:01:13.890627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([3., 4.]), tensor([1, 1]))\n",
      "Max:\t tensor([3., 4.])\n",
      "Argmax:\t tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(t.max(dim=0))  # Returns two values: max and argmax\n",
    "print('Max:\\t', t.max(dim=0)[0])    # Maximum values\n",
    "print('Argmax:\\t', t.max(dim=0)[1])    # Index of maximum values along dim=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Manipulation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View (Reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:07:57.101101Z",
     "start_time": "2019-05-13T03:07:57.096719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[[0, 1, 2], [3, 4, 5]],\n",
    "              [[6, 7, 8], [9, 10, 11]]])\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:08:33.369772Z",
     "start_time": "2019-05-13T03:08:33.365360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view([-1, 3]))\n",
    "print(ft.view([-1, 3]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:09:18.840338Z",
     "start_time": "2019-05-13T03:09:18.835934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.]],\n",
      "\n",
      "        [[ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view([-1, 1, 3]))\n",
    "print(ft.view([-1, 1, 3]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:12:45.996518Z",
     "start_time": "2019-05-13T03:12:45.992150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "ft = torch.FloatTensor([[0], [1], [2]])\n",
    "print(ft)\n",
    "print(ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:13:03.207724Z",
     "start_time": "2019-05-13T03:13:03.203364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.squeeze())\n",
    "print(ft.squeeze().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:13:31.439705Z",
     "start_time": "2019-05-13T03:13:31.436470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "ft = torch.Tensor([0, 1, 2])\n",
    "print(ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:13:45.761724Z",
     "start_time": "2019-05-13T03:13:45.745551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.]])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.unsqueeze(0))\n",
    "print(ft.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:14:04.948906Z",
     "start_time": "2019-05-13T03:14:04.944150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.]])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view(1, -1))\n",
    "print(ft.view(1, -1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:36:13.874101Z",
     "start_time": "2019-05-13T03:36:13.869574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(ft.unsqueeze(1))\n",
    "print(ft.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:36:30.870998Z",
     "start_time": "2019-05-13T03:36:30.866359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(ft.unsqueeze(-1))\n",
    "print(ft.unsqueeze(-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:37:41.744704Z",
     "start_time": "2019-05-13T03:37:41.740882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "lt = torch.LongTensor([1, 2, 3, 4])\n",
    "print(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:37:46.020059Z",
     "start_time": "2019-05-13T03:37:46.016443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "print(lt.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:38:13.260700Z",
     "start_time": "2019-05-13T03:38:13.257100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "bt = torch.ByteTensor([True, False, False, True])\n",
    "print(bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:39:57.242329Z",
     "start_time": "2019-05-13T03:39:57.238180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1])\n",
      "tensor([1., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(bt.long())\n",
    "print(bt.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:40:40.717390Z",
     "start_time": "2019-05-13T03:40:40.713924Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "y = torch.FloatTensor([[5, 6], [7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:41:56.446281Z",
     "start_time": "2019-05-13T03:41:56.429378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat([x, y], dim=0))\n",
    "print(torch.cat([x, y], dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:42:46.234161Z",
     "start_time": "2019-05-13T03:42:46.230513Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([1, 4])\n",
    "y = torch.FloatTensor([2, 5])\n",
    "z = torch.FloatTensor([3, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:43:32.749517Z",
     "start_time": "2019-05-13T03:43:32.744618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack([x, y, z]))\n",
    "print(torch.stack([x, y, z], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:51:51.388531Z",
     "start_time": "2019-05-13T03:51:51.384009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Following code is same code as `torch.stack([x, y, z])`\n",
    "print(torch.cat([x.unsqueeze(0), y.unsqueeze(0), z.unsqueeze(0)], dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ones and Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:52:31.873270Z",
     "start_time": "2019-05-13T03:52:31.869330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [2., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[0, 1, 2], [2, 1, 0]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:53:38.638581Z",
     "start_time": "2019-05-13T03:53:38.621872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones_like(x))  # make a matrix, filled with 1. (with x's shape)\n",
    "print(torch.zeros_like(x))  # make a matrix, filled with 0. (with x's shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-place Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:54:17.304100Z",
     "start_time": "2019-05-13T03:54:17.300895Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:54:28.829021Z",
     "start_time": "2019-05-13T03:54:28.824281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.mul(2.))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:54:40.438444Z",
     "start_time": "2019-05-13T03:54:40.433898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.mul_(2.))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Hypothesis:\n",
    "$$ y = Wx + b$$\n",
    "(W: weight, b: bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:58:57.581560Z",
     "start_time": "2019-05-13T03:58:57.577549Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T03:59:23.724913Z",
     "start_time": "2019-05-13T03:59:23.709404Z"
    }
   },
   "outputs": [],
   "source": [
    "# Weight와 bias를 0으로 초기화\n",
    "W = torch.zeros(1, requires_grad=True)  # requires_grad: 학습 가능하도록 지정\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute loss\n",
    "Mean Squared Error (MSE):\n",
    "$$ cost(W,b) = \\frac{1}{m}\\Sigma^{m}_{i=1}(H(x^{(i)}) - y^{(i)})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:02:13.959142Z",
     "start_time": "2019-05-13T04:02:13.944168Z"
    }
   },
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis - y_train) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.optim 라이브러리 사용\n",
    "    - [W, b]는 학습할 tensor들\n",
    "    - lr=0.01은 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:03:55.017205Z",
     "start_time": "2019-05-13T04:03:55.014600Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:03:55.664023Z",
     "start_time": "2019-05-13T04:03:55.661113Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W, b], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:04:54.628051Z",
     "start_time": "2019-05-13T04:04:54.570919Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()  # 혹시 있을지도 모르는 gradient를 0으로 초기화\n",
    "cost.backward()  # backward로 gradient 계산\n",
    "optimizer.step()  # step()으로 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:10:57.075189Z",
     "start_time": "2019-05-13T04:10:56.940143Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "\n",
    "# Weight와 bias를 0으로 초기화\n",
    "W = torch.zeros(1, requires_grad=True)  # requires_grad: 학습 가능하도록 지정\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr=0.01)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    hypothesis = x_train * W + b\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    optimizer.zero_grad()  # 혹시 있을지도 모르는 gradient를 0으로 초기화\n",
    "    cost.backward()  # backward로 gradient 계산\n",
    "    optimizer.step()  # step()으로 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper Look at GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis (Linear Regression)\n",
    "$$ H(x) = Wx + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:17:13.952001Z",
     "start_time": "2019-05-13T04:17:13.948960Z"
    }
   },
   "outputs": [],
   "source": [
    "W = torch.zeros(1, requires_grad=True)\n",
    "# b = torch.zeros(1, requires_grad=True)\n",
    "# hypothesis = x_train * W + b\n",
    "hypothesis = x_train * W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:17:47.198546Z",
     "start_time": "2019-05-13T04:17:47.195031Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function: MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE)\n",
    "$$ cost(W) = \\frac{1}{m}\\Sigma_{i=1}^{m}(H(x^{(i)}) - y^{(i)})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:19:51.688641Z",
     "start_time": "2019-05-13T04:19:51.685660Z"
    }
   },
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis - y_train) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent: The Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ cost(W) = \\frac{1}{m}\\Sigma_{i=1}^{m}(Wx^{(i)} - y^{(i)})^2 $$\n",
    "$$ \\nabla W = \\frac{\\delta cost}{\\delta W} = \\frac{2}{m}\\Sigma^{m}_{i=1}(Wx^{(i)} - y^{(i)})x^{(i)} $$\n",
    "$$ W: W - \\alpha \\nabla W $$\n",
    "alpha: learning rate, W: gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:31:54.775901Z",
     "start_time": "2019-05-13T04:31:54.765836Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad has been used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-b8f1e5207a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad has been used in an in-place operation."
     ]
    }
   ],
   "source": [
    "gradient = 2 * torch.mean((hypothesis - y_train) * x_train)\n",
    "lr = 0.1\n",
    "W -= lr * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:33:42.204598Z",
     "start_time": "2019-05-13T04:33:42.194310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/10 W: 0.000, Cost: 4.666667\n",
      "Epoch    1/10 W: 1.400, Cost: 0.746666\n",
      "Epoch    2/10 W: 0.840, Cost: 0.119467\n",
      "Epoch    3/10 W: 1.064, Cost: 0.019115\n",
      "Epoch    4/10 W: 0.974, Cost: 0.003058\n",
      "Epoch    5/10 W: 1.010, Cost: 0.000489\n",
      "Epoch    6/10 W: 0.996, Cost: 0.000078\n",
      "Epoch    7/10 W: 1.002, Cost: 0.000013\n",
      "Epoch    8/10 W: 0.999, Cost: 0.000002\n",
      "Epoch    9/10 W: 1.000, Cost: 0.000000\n",
      "Epoch   10/10 W: 1.000, Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "# 모델 초기화\n",
    "W = torch.zeros(1)\n",
    "\n",
    "# learning rate 설정\n",
    "lr = 0.1\n",
    "nb_epochs = 10\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train * W\n",
    "    \n",
    "    # cost gradient 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    gradient = torch.sum((W * x_train - y_train) * x_train)\n",
    "    print('Epoch {:4d}/{} W: {:.3f}, Cost: {:.6f}'.format(\n",
    "    epoch, nb_epochs, W.item(), cost.item()\n",
    "    ))\n",
    "\n",
    "    # cost gradient로 H(x) 개선\n",
    "    W -= lr * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:37:03.075695Z",
     "start_time": "2019-05-13T04:37:03.071476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: tensor([1.0000])\n",
      "hypothesis: tensor([[0.9999],\n",
      "        [1.9998],\n",
      "        [2.9997]])\n"
     ]
    }
   ],
   "source": [
    "print('W:', W)\n",
    "print('hypothesis:', hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Quiz 1 (x1) | Quiz 2 (x2) | Quiz 3 (x3) | Final (y) |\n",
    "|:---:|:---:|:---:|:---:|\n",
    "| 73  | 80  | 75  | 152  |\n",
    "| 93  | 88  | 93  | 185  |\n",
    "| 89  | 91  | 80  | 180  |\n",
    "| 96  | 98  | 100  | 196  |\n",
    "| 73  | 66  | 70  | 142  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:44:32.987646Z",
     "start_time": "2019-05-13T04:44:32.983193Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H(x) = Wx + b $$\n",
    "x라는 vector와 W라는 matrix의 곱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H(x) = w_1 x_1 + w_2 x_2 + w_3 x_3 + b $$\n",
    "입력변수가 3개라면 weight도 3개!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Code with torch.optim(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T04:53:41.860418Z",
     "start_time": "2019-05-13T04:53:41.854132Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "# 모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad=True)  # (3,1)모양을 가진다\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# optimizer설정\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T05:01:21.663724Z",
     "start_time": "2019-05-13T05:01:21.646521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    1/20 hypothesis: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]) Cost: 9298.520508\n",
      "Epoch    2/20 hypothesis: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]) Cost: 2915.712402\n",
      "Epoch    3/20 hypothesis: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]) Cost: 915.040527\n",
      "Epoch    4/20 hypothesis: tensor([137.7967, 165.6247, 163.1911, 177.7112, 126.3307]) Cost: 287.936096\n",
      "Epoch    5/20 hypothesis: tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]) Cost: 91.371071\n",
      "Epoch    6/20 hypothesis: tensor([148.1035, 178.0143, 175.3980, 191.0042, 135.7812]) Cost: 29.758249\n",
      "Epoch    7/20 hypothesis: tensor([150.1744, 180.5042, 177.8509, 193.6753, 137.6805]) Cost: 10.445267\n",
      "Epoch    8/20 hypothesis: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]) Cost: 4.391237\n",
      "Epoch    9/20 hypothesis: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]) Cost: 2.493121\n",
      "Epoch   10/20 hypothesis: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]) Cost: 1.897688\n",
      "Epoch   11/20 hypothesis: tensor([152.5485, 183.3609, 180.6640, 196.7389, 139.8602]) Cost: 1.710552\n",
      "Epoch   12/20 hypothesis: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]) Cost: 1.651416\n",
      "Epoch   13/20 hypothesis: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]) Cost: 1.632369\n",
      "Epoch   14/20 hypothesis: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]) Cost: 1.625924\n",
      "Epoch   15/20 hypothesis: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]) Cost: 1.623420\n",
      "Epoch   16/20 hypothesis: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]) Cost: 1.622152\n",
      "Epoch   17/20 hypothesis: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]) Cost: 1.621261\n",
      "Epoch   18/20 hypothesis: tensor([152.7999, 183.6688, 180.9644, 197.0661, 140.0963]) Cost: 1.620501\n",
      "Epoch   19/20 hypothesis: tensor([152.8014, 183.6715, 180.9665, 197.0686, 140.0985]) Cost: 1.619757\n",
      "Epoch   20/20 hypothesis: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.0999]) Cost: 1.619046\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train.matmul(W) + b  # or .mm or @\n",
    "    \n",
    "    # Cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:6f}'.format(\n",
    "        epoch,\n",
    "        nb_epochs,\n",
    "        hypothesis.squeeze().detach(),  # detach(): 현재의 계산 기록으로 분리시키고 이후에 일어나는 일은 추적하지 않도록 함\n",
    "        cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nn.Module을 상속해서 모델 생성\n",
    "- nn.Linear(3, 1)\n",
    "    - 입력차원: 3\n",
    "    - 출력차원: 1\n",
    "- Hypothesis의 계산은 forward()에서!\n",
    "- Gradient의 계산은 PyTorch가 알아서 해준다. (backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T05:18:31.157039Z",
     "start_time": "2019-05-13T05:18:31.151361Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = MultivariateLinearRegressionModel()\n",
    "hypothesis = model(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F.mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.nn.functional에서 제공하는 loss function 사용\n",
    "- 쉽게 다른 loss와 교체 가능! (l1_loss, smooth_l1_loss 등등...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T05:20:02.539281Z",
     "start_time": "2019-05-13T05:20:02.524243Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Cost 계산\n",
    "cost = F.mse_loss(hypothesis, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full code with torch.optim (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T05:29:53.233783Z",
     "start_time": "2019-05-13T05:29:53.227914Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "# 모델 초기화\n",
    "model = MultivariateLinearRegressionModel()\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)  # nn.Module에서 parameter를 불러와 optimizer를 적용하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T05:31:48.568387Z",
     "start_time": "2019-05-13T05:31:48.537944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Hypothesis: tensor([ -88.7396, -107.5824, -105.5100, -114.8378,  -82.3850]) Cost: 74408.937500\n",
      "Epoch    1/20 Hypothesis: tensor([17.7877, 20.4566, 20.6484, 22.5456, 15.2767]) Cost: 23325.125000\n",
      "Epoch    2/20 Hypothesis: tensor([77.4282, 92.1411, 91.2798, 99.4614, 69.9542]) Cost: 7313.063477\n",
      "Epoch    3/20 Hypothesis: tensor([110.8184, 132.2747, 130.8236, 142.5237, 100.5663]) Cost: 2294.130859\n",
      "Epoch    4/20 Hypothesis: tensor([129.5121, 154.7443, 152.9627, 166.6326, 117.7051]) Cost: 720.962280\n",
      "Epoch    5/20 Hypothesis: tensor([139.9778, 167.3244, 165.3575, 180.1303, 127.3008]) Cost: 227.856186\n",
      "Epoch    6/20 Hypothesis: tensor([145.8369, 174.3676, 172.2968, 187.6870, 132.6733]) Cost: 73.292740\n",
      "Epoch    7/20 Hypothesis: tensor([149.1169, 178.3111, 176.1817, 191.9177, 135.6814]) Cost: 24.844398\n",
      "Epoch    8/20 Hypothesis: tensor([150.9530, 180.5191, 178.3567, 194.2863, 137.3658]) Cost: 9.657643\n",
      "Epoch    9/20 Hypothesis: tensor([151.9807, 181.7554, 179.5743, 195.6123, 138.3090]) Cost: 4.896489\n",
      "Epoch   10/20 Hypothesis: tensor([152.5559, 182.4478, 180.2559, 196.3546, 138.8374]) Cost: 3.403280\n",
      "Epoch   11/20 Hypothesis: tensor([152.8776, 182.8356, 180.6375, 196.7701, 139.1334]) Cost: 2.934355\n",
      "Epoch   12/20 Hypothesis: tensor([153.0575, 183.0529, 180.8510, 197.0027, 139.2994]) Cost: 2.786501\n",
      "Epoch   13/20 Hypothesis: tensor([153.1579, 183.1747, 180.9705, 197.1328, 139.3925]) Cost: 2.739279\n",
      "Epoch   14/20 Hypothesis: tensor([153.2139, 183.2431, 181.0373, 197.2056, 139.4449]) Cost: 2.723625\n",
      "Epoch   15/20 Hypothesis: tensor([153.2450, 183.2816, 181.0746, 197.2463, 139.4745]) Cost: 2.717817\n",
      "Epoch   16/20 Hypothesis: tensor([153.2621, 183.3033, 181.0954, 197.2690, 139.4913]) Cost: 2.715152\n",
      "Epoch   17/20 Hypothesis: tensor([153.2715, 183.3156, 181.1070, 197.2817, 139.5010]) Cost: 2.713429\n",
      "Epoch   18/20 Hypothesis: tensor([153.2764, 183.3227, 181.1134, 197.2887, 139.5066]) Cost: 2.712028\n",
      "Epoch   19/20 Hypothesis: tensor([153.2790, 183.3268, 181.1169, 197.2925, 139.5100]) Cost: 2.710709\n",
      "Epoch   20/20 Hypothesis: tensor([153.2801, 183.3293, 181.1188, 197.2946, 139.5121]) Cost: 2.709455\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "    \n",
    "    # Cost 계산\n",
    "    cost = F.mse_loss(hypothesis, y_train)\n",
    "    \n",
    "    # Cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"Epoch {:4d}/{} Hypothesis: {} Cost: {:6f}\".format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data in the Real World: Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 엄청난 양의 데이터를 한번에 학습시킬 수 없다!\n",
    "    - 너무 느리다.\n",
    "    - 하드웨어적으로 불가능하다. (정해진 메모리 용량)\n",
    "- 그렇다면 일부분의 데이터로만 학습하면 어떨까?\n",
    "    - 전체 데이터를 균일하게 나눠서 학습하자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.utils.data.Dataset 상속\n",
    "- \\_\\_len\\_\\_()\n",
    "    - 이 데이터셋의 총 데이터 수\n",
    "- \\_\\_getitem\\_\\_()\n",
    "    - 어떠한 인덱스 idx를 받았을 때, 그에 상응하는 입출력 데이터 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T05:56:33.342120Z",
     "start_time": "2019-05-13T05:56:33.334430Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                      [93, 88, 93], \n",
    "                      [89, 91, 90],\n",
    "                      [96, 98, 100],\n",
    "                      [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T05:56:33.844773Z",
     "start_time": "2019-05-13T05:56:33.841211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T05:56:44.901799Z",
     "start_time": "2019-05-13T05:56:44.897333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[73., 80., 75.],\n",
       "         [93., 88., 93.]]), tensor([[152.],\n",
       "         [185.]]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.utils.data.DataLoader 사용\n",
    "- batch_size=2\n",
    "    - 각 minibatch의 크기\n",
    "    - 통상적으로 2의 제곱수로 설정한다. (16, 32, 64, 128, 256, 512, ...)\n",
    "- shuffle=True\n",
    "    - Epoch 마다 데이터셋을 섞어서, 데이터가 학습되는 순서를 바꾼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:00:51.967477Z",
     "start_time": "2019-05-13T06:00:51.964504Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Code with Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- enumerate(dataloader)\n",
    "    - minibatch 인덱스와 데이터를 받음\n",
    "- len(dataloader)\n",
    "    - 한 epoch당 minibatch 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:02:17.495444Z",
     "start_time": "2019-05-13T06:02:17.492150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)  # [0번째, 1번째], [2번째, 3번째], [4번째]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:12:33.884938Z",
     "start_time": "2019-05-13T06:12:33.858573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch: 1/3 Cost: 3.453684\n",
      "Epoch    0/20 Batch: 2/3 Cost: 3.479603\n",
      "Epoch    0/20 Batch: 3/3 Cost: 3.629660\n",
      "Epoch    1/20 Batch: 1/3 Cost: 3.238724\n",
      "Epoch    1/20 Batch: 2/3 Cost: 3.896069\n",
      "Epoch    1/20 Batch: 3/3 Cost: 2.529010\n",
      "Epoch    2/20 Batch: 1/3 Cost: 4.283844\n",
      "Epoch    2/20 Batch: 2/3 Cost: 2.056861\n",
      "Epoch    2/20 Batch: 3/3 Cost: 5.744820\n",
      "Epoch    3/20 Batch: 1/3 Cost: 4.162724\n",
      "Epoch    3/20 Batch: 2/3 Cost: 2.031227\n",
      "Epoch    3/20 Batch: 3/3 Cost: 2.665230\n",
      "Epoch    4/20 Batch: 1/3 Cost: 3.937222\n",
      "Epoch    4/20 Batch: 2/3 Cost: 1.944501\n",
      "Epoch    4/20 Batch: 3/3 Cost: 1.819675\n",
      "Epoch    5/20 Batch: 1/3 Cost: 4.050185\n",
      "Epoch    5/20 Batch: 2/3 Cost: 2.135216\n",
      "Epoch    5/20 Batch: 3/3 Cost: 1.980330\n",
      "Epoch    6/20 Batch: 1/3 Cost: 0.355285\n",
      "Epoch    6/20 Batch: 2/3 Cost: 4.936532\n",
      "Epoch    6/20 Batch: 3/3 Cost: 4.091953\n",
      "Epoch    7/20 Batch: 1/3 Cost: 3.448509\n",
      "Epoch    7/20 Batch: 2/3 Cost: 1.991413\n",
      "Epoch    7/20 Batch: 3/3 Cost: 3.143132\n",
      "Epoch    8/20 Batch: 1/3 Cost: 0.471679\n",
      "Epoch    8/20 Batch: 2/3 Cost: 4.886042\n",
      "Epoch    8/20 Batch: 3/3 Cost: 3.996827\n",
      "Epoch    9/20 Batch: 1/3 Cost: 3.436422\n",
      "Epoch    9/20 Batch: 2/3 Cost: 2.426628\n",
      "Epoch    9/20 Batch: 3/3 Cost: 2.122051\n",
      "Epoch   10/20 Batch: 1/3 Cost: 2.257171\n",
      "Epoch   10/20 Batch: 2/3 Cost: 1.459549\n",
      "Epoch   10/20 Batch: 3/3 Cost: 8.451257\n",
      "Epoch   11/20 Batch: 1/3 Cost: 1.901392\n",
      "Epoch   11/20 Batch: 2/3 Cost: 3.715204\n",
      "Epoch   11/20 Batch: 3/3 Cost: 2.249222\n",
      "Epoch   12/20 Batch: 1/3 Cost: 0.813434\n",
      "Epoch   12/20 Batch: 2/3 Cost: 4.516393\n",
      "Epoch   12/20 Batch: 3/3 Cost: 3.604992\n",
      "Epoch   13/20 Batch: 1/3 Cost: 2.462234\n",
      "Epoch   13/20 Batch: 2/3 Cost: 3.459187\n",
      "Epoch   13/20 Batch: 3/3 Cost: 2.431689\n",
      "Epoch   14/20 Batch: 1/3 Cost: 2.178760\n",
      "Epoch   14/20 Batch: 2/3 Cost: 3.767648\n",
      "Epoch   14/20 Batch: 3/3 Cost: 1.703404\n",
      "Epoch   15/20 Batch: 1/3 Cost: 0.555458\n",
      "Epoch   15/20 Batch: 2/3 Cost: 3.121789\n",
      "Epoch   15/20 Batch: 3/3 Cost: 7.106988\n",
      "Epoch   16/20 Batch: 1/3 Cost: 3.391465\n",
      "Epoch   16/20 Batch: 2/3 Cost: 2.012299\n",
      "Epoch   16/20 Batch: 3/3 Cost: 3.224648\n",
      "Epoch   17/20 Batch: 1/3 Cost: 0.522003\n",
      "Epoch   17/20 Batch: 2/3 Cost: 4.687440\n",
      "Epoch   17/20 Batch: 3/3 Cost: 3.827284\n",
      "Epoch   18/20 Batch: 1/3 Cost: 1.975808\n",
      "Epoch   18/20 Batch: 2/3 Cost: 3.705448\n",
      "Epoch   18/20 Batch: 3/3 Cost: 2.319653\n",
      "Epoch   19/20 Batch: 1/3 Cost: 3.913563\n",
      "Epoch   19/20 Batch: 2/3 Cost: 1.275805\n",
      "Epoch   19/20 Batch: 3/3 Cost: 4.640469\n",
      "Epoch   20/20 Batch: 1/3 Cost: 2.582699\n",
      "Epoch   20/20 Batch: 2/3 Cost: 5.679107\n",
      "Epoch   20/20 Batch: 3/3 Cost: 1.310546\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_train, y_train = samples\n",
    "        \n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        # Cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        # Cost로 H(x) 계산\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch {:4d}/{} Batch: {}/{} Cost: {:6f}'.format(\n",
    "            epoch, nb_epochs, batch_idx + 1, len(dataloader), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hypothesis__:\n",
    "$$ H(X) = \\frac{1}{1 + \\exp^{-W^T X}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cost__:\n",
    "$$ cost(W) = -\\frac{1}{m} \\Sigma {y\\log (H(x)) + (1-y)(\\log (1 - H(x))} $$\n",
    "- If y ~ H(x), cost is near 0\n",
    "- If y != H(x), cost is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Weight Update via Gradient Descent__:\n",
    "$$ W := W - \\alpha \\frac{\\delta}{\\delta W}cost(W) $$\n",
    "- alpha: Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:21:11.382962Z",
     "start_time": "2019-05-13T06:21:11.379791Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:21:26.504358Z",
     "start_time": "2019-05-13T06:21:26.487769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4794ec42d0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:22:15.661380Z",
     "start_time": "2019-05-13T06:22:15.657254Z"
    }
   },
   "outputs": [],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following classification problem:\n",
    "- given the number of hours each student spent watching the lecture and working in the code lab\n",
    "- predict whether the student passed or failed a course\n",
    "- For example, the first (index 0) student watched the lecture for 1 hour and spent 2 hours in the lab session ([1, 2])\n",
    "    - and ended up failing the course([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:27:41.935531Z",
     "start_time": "2019-05-13T06:27:41.932671Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:27:59.043481Z",
     "start_time": "2019-05-13T06:27:59.040502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H(X) = \\frac{1}{1 + \\exp^{-W^T X}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:29:41.958844Z",
     "start_time": "2019-05-13T06:29:41.940446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e^1 equals: tensor([2.7183])\n"
     ]
    }
   ],
   "source": [
    "print('e^1 equals:', torch.exp(torch.FloatTensor([1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:30:16.277006Z",
     "start_time": "2019-05-13T06:30:16.273755Z"
    }
   },
   "outputs": [],
   "source": [
    "W = torch.zeros((2, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:30:45.377745Z",
     "start_time": "2019-05-13T06:30:45.374426Z"
    }
   },
   "outputs": [],
   "source": [
    "hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:30:54.875307Z",
     "start_time": "2019-05-13T06:30:54.871438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<MulBackward0>)\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)\n",
    "print(hypothesis.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use `torch.sigmoid()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:32:15.756160Z",
     "start_time": "2019-05-13T06:32:15.738866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/(1+e^{-1}) equals: tensor([0.7311])\n"
     ]
    }
   ],
   "source": [
    "print('1/(1+e^{-1}) equals:', torch.sigmoid(torch.FloatTensor([1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:32:46.907964Z",
     "start_time": "2019-05-13T06:32:46.893033Z"
    }
   },
   "outputs": [],
   "source": [
    "hypothesis = torch.sigmoid(x_train.matmul(W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:32:57.666548Z",
     "start_time": "2019-05-13T06:32:57.663030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)\n",
    "print(hypothesis.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ cost(W) = -\\frac{1}{m}\\Sigma y\\log (H(x)) + (1 - y)(\\log (1 - H(x)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:34:27.788997Z",
     "start_time": "2019-05-13T06:34:27.784990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:36:18.821886Z",
     "start_time": "2019-05-13T06:36:18.816433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6931], grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(y_train[0] * torch.log(hypothesis[0]) + \n",
    " (1 - y_train[0]) * torch.log(1 - hypothesis[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:37:44.019967Z",
     "start_time": "2019-05-13T06:37:44.015744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931]], grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "losses = -(y_train * torch.log(hypothesis) + (1 - y_train) * torch.log(1 - hypothesis))\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:38:15.747515Z",
     "start_time": "2019-05-13T06:38:15.744142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6931, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "cost = losses.mean()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:38:47.483899Z",
     "start_time": "2019-05-13T06:38:47.468378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simpler version\n",
    "F.binary_cross_entropy(hypothesis, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:43:07.677593Z",
     "start_time": "2019-05-13T06:43:07.542169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 0.693147\n",
      "Epoch  100/1000 Cost: 0.134722\n",
      "Epoch  200/1000 Cost: 0.080643\n",
      "Epoch  300/1000 Cost: 0.057900\n",
      "Epoch  400/1000 Cost: 0.045300\n",
      "Epoch  500/1000 Cost: 0.037261\n",
      "Epoch  600/1000 Cost: 0.031673\n",
      "Epoch  700/1000 Cost: 0.027556\n",
      "Epoch  800/1000 Cost: 0.024394\n",
      "Epoch  900/1000 Cost: 0.021888\n",
      "Epoch 1000/1000 Cost: 0.019852\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((2, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # Cost 계산\n",
    "    hypothesis = torch.sigmoid(x_train.matmul(W) + b)    # or .mm or @\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch {:4d}/{} Cost: {:.6f}\".format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:45:38.703979Z",
     "start_time": "2019-05-13T06:45:38.699641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7648e-04],\n",
      "        [3.1608e-02],\n",
      "        [3.8977e-02],\n",
      "        [9.5622e-01],\n",
      "        [9.9823e-01]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
    "print(hypothesis[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:49:58.565881Z",
     "start_time": "2019-05-13T06:49:58.562112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# 기준(0.5)을 넘는다면 True, 아니라면 False\n",
    "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "print(prediction[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:51:20.003749Z",
     "start_time": "2019-05-13T06:51:19.999249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], dtype=torch.uint8)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "# Compare with ground truth (y_train)\n",
    "print(prediction[:5])\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:54:52.284699Z",
     "start_time": "2019-05-13T06:54:52.281344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = prediction.float() == y_train\n",
    "print(correct_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher Implementation with Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:59:52.638013Z",
     "start_time": "2019-05-13T06:59:52.633430Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:59:52.962173Z",
     "start_time": "2019-05-13T06:59:52.959526Z"
    }
   },
   "outputs": [],
   "source": [
    "model = BinaryClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T06:59:53.673293Z",
     "start_time": "2019-05-13T06:59:53.647670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 Cost: 0.733120 Accuracy: 50.00%\n",
      "Epoch   20/100 Cost: 0.739900 Accuracy: 66.67%\n",
      "Epoch   40/100 Cost: 0.451816 Accuracy: 83.33%\n",
      "Epoch   60/100 Cost: 0.288507 Accuracy: 83.33%\n",
      "Epoch   80/100 Cost: 0.173718 Accuracy: 100.00%\n",
      "Epoch  100/100 Cost: 0.140431 Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 20 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "        correct_prediction = prediction.float() == y_train\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
    "        print('Epoch {:4d}/{} Cost: {:6f} Accuracy: {:2.2f}%'.format(\n",
    "            epoch, nb_epochs, cost.item(), accuracy * 100\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert numbers to probabilities with softmax\n",
    "$$ P(class = i) = \\frac{\\exp^i}{\\Sigma \\exp^i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T07:19:56.709927Z",
     "start_time": "2019-05-13T07:19:56.707039Z"
    }
   },
   "outputs": [],
   "source": [
    "z = torch.FloatTensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T07:20:31.622245Z",
     "start_time": "2019-05-13T07:20:31.618379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch has `softmax` function\n",
    "hypothesis = F.softmax(z, dim=0)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T07:20:51.898119Z",
     "start_time": "2019-05-13T07:20:51.893922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The probabilities should add up to 1\n",
    "hypothesis.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H(P, Q) = -\\mathbb{E}_{x~P(x)}[\\log Q(x)] = - \\Sigma_{x \\in X} P(x) \\log Q(x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-class clasification, we use the cross-entropy loss\n",
    "$$ L = \\frac{1}{N} \\Sigma{-y \\log (\\hat{y})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T07:37:10.813030Z",
     "start_time": "2019-05-13T07:37:10.808678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2618, 0.1860, 0.1656, 0.2060, 0.1806],\n",
      "        [0.1655, 0.1989, 0.2616, 0.2549, 0.1191],\n",
      "        [0.2219, 0.1871, 0.2615, 0.2264, 0.1032]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.rand(3, 5, requires_grad=True)\n",
    "hypothesis = F.softmax(z, dim=1)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T07:40:23.181437Z",
     "start_time": "2019-05-13T07:40:23.177601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randint(5, (3,)).long()    # (low_num, shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T07:44:05.024807Z",
     "start_time": "2019-05-13T07:44:05.008289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = torch.zeros_like(hypothesis)\n",
    "y_one_hot.scatter_(1, y.unsqueeze(1), 1)    # scatter(dim, index, source): source값을 index에 맞게 뿌려주는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T07:57:23.877028Z",
     "start_time": "2019-05-13T07:57:23.872831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5502, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy Loss with torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:02:47.888621Z",
     "start_time": "2019-05-13T08:02:47.883904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3403, -1.6821, -1.7979, -1.5797, -1.7116],\n",
       "        [-1.7990, -1.6149, -1.3408, -1.3671, -2.1276],\n",
       "        [-1.5057, -1.6760, -1.3414, -1.4856, -2.2712]], grad_fn=<LogBackward>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low level\n",
    "torch.log(F.softmax(z, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:03:00.263583Z",
     "start_time": "2019-05-13T08:03:00.259089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3403, -1.6821, -1.7979, -1.5797, -1.7116],\n",
       "        [-1.7990, -1.6149, -1.3408, -1.3671, -2.1276],\n",
       "        [-1.5057, -1.6760, -1.3414, -1.4856, -2.2712]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High level\n",
    "F.log_softmax(z, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:08:30.073533Z",
     "start_time": "2019-05-13T08:08:30.067604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5502, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low level\n",
    "(y_one_hot * -torch.log(F.softmax(z, dim=1))).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:09:07.495581Z",
     "start_time": "2019-05-13T08:09:07.478850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5502, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High level\n",
    "F.nll_loss(F.log_softmax(z, dim=1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:09:45.471097Z",
     "start_time": "2019-05-13T08:09:45.466914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5502, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(z, y)    # combines F.log_softmax & F.nll_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Low-level Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:19:21.476035Z",
     "start_time": "2019-05-13T08:19:21.470042Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
    "\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:19:21.876947Z",
     "start_time": "2019-05-13T08:19:21.674728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.901535\n",
      "Epoch  200/1000 Cost: 0.839114\n",
      "Epoch  300/1000 Cost: 0.807826\n",
      "Epoch  400/1000 Cost: 0.788472\n",
      "Epoch  500/1000 Cost: 0.774822\n",
      "Epoch  600/1000 Cost: 0.764449\n",
      "Epoch  700/1000 Cost: 0.756191\n",
      "Epoch  800/1000 Cost: 0.749398\n",
      "Epoch  900/1000 Cost: 0.743671\n",
      "Epoch 1000/1000 Cost: 0.738749\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # Cost 계산 (1)\n",
    "    hypothesis = F.softmax(x_train.matmul(W) + b, dim=1)  # or .mm or @\n",
    "    y_one_hot = torch.zeros_like(hypothesis)\n",
    "    y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
    "    cost = (y_one_hot * -torch.log(F.softmax(hypothesis, dim=1))).sum(dim=1).mean()\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:25:58.207489Z",
     "start_time": "2019-05-13T08:25:58.084402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.761050\n",
      "Epoch  200/1000 Cost: 0.689991\n",
      "Epoch  300/1000 Cost: 0.643229\n",
      "Epoch  400/1000 Cost: 0.604117\n",
      "Epoch  500/1000 Cost: 0.568255\n",
      "Epoch  600/1000 Cost: 0.533922\n",
      "Epoch  700/1000 Cost: 0.500291\n",
      "Epoch  800/1000 Cost: 0.466908\n",
      "Epoch  900/1000 Cost: 0.433507\n",
      "Epoch 1000/1000 Cost: 0.399962\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # Cost 계산 (2)\n",
    "    z = x_train.matmul(W) + b\n",
    "    cost = F.cross_entropy(z, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High level implementation with nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:28:51.485621Z",
     "start_time": "2019-05-13T08:28:51.481376Z"
    }
   },
   "outputs": [],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4, 3)    # Input: 4, Output: 3\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:28:59.256130Z",
     "start_time": "2019-05-13T08:28:59.253146Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:30:55.199302Z",
     "start_time": "2019-05-13T08:30:55.061080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.709794\n",
      "Epoch  100/1000 Cost: 0.728848\n",
      "Epoch  200/1000 Cost: 0.647355\n",
      "Epoch  300/1000 Cost: 0.590688\n",
      "Epoch  400/1000 Cost: 0.540985\n",
      "Epoch  500/1000 Cost: 0.494063\n",
      "Epoch  600/1000 Cost: 0.448365\n",
      "Epoch  700/1000 Cost: 0.403141\n",
      "Epoch  800/1000 Cost: 0.358004\n",
      "Epoch  900/1000 Cost: 0.312970\n",
      "Epoch 1000/1000 Cost: 0.269591\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # Cost 계산 (3)\n",
    "    cost = F.cross_entropy(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 normal distribution에 맞도록 normalize해주는 작업 등이 포함된다.\n",
    "$$ x'_j = \\frac{x_j - \\mu_j}{\\sigma_j} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigma: standard deviation, mu: 평균값(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:57:28.815776Z",
     "start_time": "2019-05-13T08:57:28.811289Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 입력\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:57:32.444547Z",
     "start_time": "2019-05-13T08:57:32.441908Z"
    }
   },
   "outputs": [],
   "source": [
    "mu = x_train.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:57:33.702306Z",
     "start_time": "2019-05-13T08:57:33.699542Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma = x_train.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:57:42.614281Z",
     "start_time": "2019-05-13T08:57:42.611690Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_x_train = (x_train - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T08:57:47.250741Z",
     "start_time": "2019-05-13T08:57:47.247390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0674, -0.3758, -0.8398],\n",
      "        [ 0.7418,  0.2778,  0.5863],\n",
      "        [ 0.3799,  0.5229,  0.3486],\n",
      "        [ 1.0132,  1.0948,  1.1409],\n",
      "        [-1.0674, -1.5197, -1.2360]])\n"
     ]
    }
   ],
   "source": [
    "print(norm_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:17:49.295860Z",
     "start_time": "2019-05-13T09:17:49.293302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using torchvision.datasets.dsets\n",
    "import torchvision.datasets as dsets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:18:36.980715Z",
     "start_time": "2019-05-13T09:18:25.253883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:21:01.146214Z",
     "start_time": "2019-05-13T09:21:01.143241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Warning: Changed from torch.utils.DataLoader → torch.utils.data.DataLoader (please check document)\n",
    "dataloader = torch.utils.data.DataLoader(mnist_train, batch_size=1000, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:21:41.694861Z",
     "start_time": "2019-05-13T09:21:41.691498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:28:55.153042Z",
     "start_time": "2019-05-13T09:28:55.149865Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:36:42.341417Z",
     "start_time": "2019-05-13T09:35:49.548474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 6.185204506\n",
      "Epoch: 0002 cost = 3.368914366\n",
      "Epoch: 0003 cost = 2.446892977\n",
      "Epoch: 0004 cost = 2.002809286\n",
      "Epoch: 0005 cost = 1.737741828\n",
      "Epoch: 0006 cost = 1.559336424\n",
      "Epoch: 0007 cost = 1.430028677\n",
      "Epoch: 0008 cost = 1.331678271\n",
      "Epoch: 0009 cost = 1.253919244\n",
      "Epoch: 0010 cost = 1.190466881\n",
      "Epoch: 0011 cost = 1.137811184\n",
      "Epoch: 0012 cost = 1.093274117\n",
      "Epoch: 0013 cost = 1.054798722\n",
      "Epoch: 0014 cost = 1.021093488\n",
      "Epoch: 0015 cost = 0.991394877\n"
     ]
    }
   ],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784 (flattened)\n",
    "linear = torch.nn.Linear(784, 10, bias=True).to(device)\n",
    "\n",
    "# initialization\n",
    "torch.nn.init.normal_(linear.weight)\n",
    "\n",
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 1000\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(linear.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(dataloader)\n",
    "    \n",
    "    for X, Y in dataloader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28*28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        # H(x)\n",
    "        hypothesis = linear(X)\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print(\"Epoch: {:04d}\".format(epoch+1), \"cost =\", \"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:40:37.876104Z",
     "start_time": "2019-05-13T09:40:37.824506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7996000051498413\n"
     ]
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28*28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:40:46.269904Z",
     "start_time": "2019-05-13T09:40:46.266131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 0, 1], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:44:11.048694Z",
     "start_time": "2019-05-13T09:44:10.889428Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:45:20.515078Z",
     "start_time": "2019-05-13T09:45:20.497833Z"
    }
   },
   "outputs": [],
   "source": [
    "r = random.randint(0, len(mnist_test) - 1)\n",
    "X_single_data = mnist_test.test_data[r:r+1].view(-1, 28*28).float().to(device)\n",
    "Y_single_data = mnist_test.test_labels[r:r+1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:46:21.767630Z",
     "start_time": "2019-05-13T09:46:21.749201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n",
      "Prediction: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Label:\", Y_single_data.item())\n",
    "single_prediction = linear(X_single_data)\n",
    "print(\"Prediction:\", torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T09:47:10.286543Z",
     "start_time": "2019-05-13T09:47:10.179928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist_test.test_data[r:r+1].view(28, 28), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
